{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes / TODO  \n",
    "\n",
    "- Random seeding  \n",
    "- Preproc transforms\n",
    "- augmentations\n",
    "   - no augmentation for validation\n",
    "- Train-Validation-Test data\n",
    "    - split train data 40 - 5\n",
    "    - infer all test data save results\n",
    "    - visualize results\n",
    "- \n",
    "    \n",
    "- Train workflow\n",
    "    - lr find\n",
    "    - more epochs ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eisen.datasets import ABCsDataset\n",
    "from eisen.models.segmentation import VNet\n",
    "from eisen.io import LoadITKFromFilename\n",
    "from eisen.transforms import (\n",
    "    ResampleITKVolumes,\n",
    "    ITKToNumpy,\n",
    "    CropCenteredSubVolumes,\n",
    "    AddChannelDimension,\n",
    "    MapValues,\n",
    "    FixedMeanStdNormalization,\n",
    "    LabelMapToOneHot,\n",
    "    StackImagesChannelwise,\n",
    "    FilterFields\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eisen.ops.losses import DiceLoss\n",
    "from eisen.ops.metrics import DiceMetric\n",
    "from eisen.utils import EisenModuleWrapper, EisenTransformWrapper\n",
    "from eisen.utils.workflows import Training\n",
    "\n",
    "from eisen.utils.logging import LoggingHook\n",
    "from eisen.utils.logging import TensorboardSummaryHook\n",
    "from eisen.utils.artifacts import SaveTorchModelHook\n",
    "\n",
    "from torchvision.transforms import Compose\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "now = datetime.now() # current date and time\n",
    "date_time = now.strftime(\"%d-%m-%Y_%H:%M:%S\")\n",
    "\n",
    "# Defining some constants\n",
    "PATH_DATA = 'Data/ABCs_training_data/'  # path of data as unpacked from the challenge files\n",
    "PATH_ARTIFACTS = f'./results/{date_time}'  # path for model results\n",
    "\n",
    "if not os.path.exists(PATH_ARTIFACTS):\n",
    "    os.system('mkdir' + \" \" + PATH_ARTIFACTS)\n",
    "\n",
    "TASK = 'task1'\n",
    "#TASK = 'task2'\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "VOLUMES_RESOLUTION = [2, 2, 1.5]\n",
    "VOLUMES_PIXEL_SIZE = [128, 128, 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TASK == 'task1':\n",
    "    n_out_chan = 5\n",
    "    label_field = 'label_task1'\n",
    "else:\n",
    "    n_out_chan = 10\n",
    "    label_field = 'label_task2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define Readers and Transforms\n",
    "In order to load data and prepare it for being used by the network, we need to operate \n",
    "I/O operations and define transforms to standardize data.\n",
    "You can add transforms or change the existing ones by editing this\n",
    "\"\"\"\n",
    "\n",
    "# readers: for images and labels\n",
    "read_tform = LoadITKFromFilename(['ct', 't1', 't2', label_field], PATH_DATA)\n",
    "\n",
    "# image manipulation transforms\n",
    "\n",
    "resample_tform_img = ResampleITKVolumes(\n",
    "    ['ct', 't1', 't2'],\n",
    "    VOLUMES_RESOLUTION,\n",
    "    'linear'\n",
    ")\n",
    "\n",
    "resample_tform_lbl = ResampleITKVolumes(\n",
    "    [label_field],\n",
    "    VOLUMES_RESOLUTION,\n",
    "    'nearest'\n",
    ")\n",
    "\n",
    "to_numpy_tform = ITKToNumpy(['ct', 't1', 't2', label_field])\n",
    "\n",
    "crop = CropCenteredSubVolumes(fields=['ct', 't1', 't2', label_field], size=VOLUMES_PIXEL_SIZE)\n",
    "\n",
    "map_intensities = MapValues(['t1', 't2'], min_value=0.0, max_value=1.0)\n",
    "\n",
    "normalize_ct = FixedMeanStdNormalization(['ct'], mean=208.0, std=388.0)\n",
    "\n",
    "if TASK == 'task1':\n",
    "    map_labels = LabelMapToOneHot([label_field], [1, 2, 3, 4, 5])\n",
    "else:\n",
    "    map_labels = LabelMapToOneHot([label_field], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "\n",
    "stack_modalities = StackImagesChannelwise(['ct', 't1', 't2'], 'image')\n",
    "preserve_only_fields = FilterFields(['image', label_field])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a transform to manipulate and load data\n",
    "train_tform = Compose([\n",
    "    read_tform,\n",
    "    resample_tform_img,\n",
    "    resample_tform_lbl,\n",
    "    to_numpy_tform,\n",
    "    crop,\n",
    "    map_intensities,\n",
    "    normalize_ct,\n",
    "    map_labels,\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Augmentations  \n",
    "- random op needs to be constant among applied fields\n",
    "- write a new wrapper for controllig random tfms\n",
    "- rewrite transforms according to the source code from torchio\n",
    "    - https://torchio.readthedocs.io/transforms/augmentation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchio\n",
    "from torchio import Subject, ScalarImage, LabelMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchio.transforms import (\n",
    "    RandomFlip,\n",
    "    RandomElasticDeformation,\n",
    "    RandomAffine,\n",
    "    RandomMotion,    \n",
    "    RandomBiasField,\n",
    "    RandomNoise,\n",
    "    OneOf,\n",
    "    \n",
    "    RandomBlur,\n",
    "    RandomSpike,\n",
    "    RandomGhosting,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EisenTransformWrapper:\n",
    "    \n",
    "    def __init__(self, transform, fields, label):\n",
    "        super(EisenTransformWrapper, self).__init__()\n",
    "        self.fields = fields\n",
    "        self.transform = transform\n",
    "        self.label = label\n",
    "\n",
    "    def __call__(self, data):\n",
    "        \n",
    "        subject = Subject(\n",
    "        ct=ScalarImage(tensor=data['ct']),  # this class is new\n",
    "        t1=ScalarImage(tensor=data['t1']),\n",
    "        t2=ScalarImage(tensor=data['t2']),\n",
    "        label=LabelMap(tensor=data[self.label]),\n",
    "        )\n",
    "        \n",
    "        transformed = self.transform(subject)\n",
    "        \n",
    "        data['ct'] = transformed['ct'].numpy()\n",
    "        data['t1'] = transformed['t1'].numpy()\n",
    "        data['t2'] = transformed['t2'].numpy()\n",
    "        data[self.label] = transformed[self.label].numpy()\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_noise = EisenTransformWrapper(RandomNoise(), fields=['ct', 't1', 't2', label_field], label=label_field)\n",
    "R_motion = EisenTransformWrapper(RandomMotion(), fields=['ct', 't1', 't2', label_field], label=label_field)\n",
    "R_bias = EisenTransformWrapper(RandomBiasField(), fields=['ct', 't1', 't2', label_field], label=label_field)\n",
    "R_flip = EisenTransformWrapper(RandomFlip(axes=(0,)), fields=['ct', 't1', 't2', label_field], label=label_field)\n",
    "R_deform = EisenTransformWrapper(OneOf({RandomAffine(): 0.8, RandomElasticDeformation(): 0.2,}), \n",
    "                            fields=['ct', 't1', 't2', label_field], label=label_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a transform to manipulate and load data\n",
    "train_tform = Compose([\n",
    "    read_tform,\n",
    "    resample_tform_img,\n",
    "    resample_tform_lbl,\n",
    "    to_numpy_tform,\n",
    "    crop,\n",
    "    map_intensities,\n",
    "    normalize_ct,\n",
    "    map_labels,\n",
    "    R_noise,\n",
    "    R_motion,\n",
    "    R_bias,\n",
    "    R_flip,\n",
    "    R_deform,\n",
    "    stack_modalities,\n",
    "    preserve_only_fields\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_tform = Compose([\n",
    "    read_tform,\n",
    "    resample_tform_img,\n",
    "    resample_tform_lbl,\n",
    "    to_numpy_tform,\n",
    "    crop,\n",
    "    map_intensities,\n",
    "    normalize_ct,\n",
    "    map_labels,\n",
    "    stack_modalities,\n",
    "    preserve_only_fields\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Val Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataset from the training set of the ABC dataset\n",
    "dataset = ABCsDataset(\n",
    "    PATH_DATA,\n",
    "    training=True,\n",
    "    flat_dir_structure=True,  # check documentation\n",
    "    transform=val_tform\n",
    ")\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split as random_split\n",
    "import numpy as np\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_set , val_set = random_split(dataset, [train_size, test_size])\n",
    "train_set.transform = train_tform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set 36\n",
      "val_set 9\n"
     ]
    }
   ],
   "source": [
    "print('train_set', len(train_set))\n",
    "print('val_set', len(val_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, shuffle=True, batch_size=2, num_workers=6)\n",
    "val_loader = DataLoader(val_set, shuffle=True, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify model and loss (building blocks)\n",
    "\n",
    "model = EisenModuleWrapper(\n",
    "    module=VNet(input_channels=3, output_channels=n_out_chan),\n",
    "    input_names=['image'],\n",
    "    output_names=['predictions']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE TASK HERE if needed!!\n",
    "loss = EisenModuleWrapper(\n",
    "    module=DiceLoss(dim=[2, 3, 4]),\n",
    "    input_names=['predictions', label_field],\n",
    "    output_names=['dice_loss']\n",
    ")\n",
    "# CHANGE TASK HERE if needed!!\n",
    "metric = EisenModuleWrapper(\n",
    "    module=DiceMetric(dim=[2, 3, 4]),\n",
    "    input_names=['predictions', label_field],\n",
    "    output_names=['dice_metric']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "    - write validation workflow\n",
    "    - use this Vnet as baseline model\n",
    "    - Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eisen.utils.workflows import Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join all blocks into a workflow (training workflow)\n",
    "training_workflow = Training(\n",
    "      model=model,\n",
    "      losses=[loss],\n",
    "      data_loader=train_loader,\n",
    "      optimizer=optimizer,\n",
    "      metrics=[metric],\n",
    "      gpu=False\n",
    ")\n",
    "\n",
    "validation_workflow = Validation(\n",
    "      model=model,\n",
    "      losses=[loss],\n",
    "      data_loader=val_loader,\n",
    "      metrics=[metric],\n",
    "      gpu=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Hook to monitor training and save models\n",
    "training_loggin_hook = LoggingHook(training_workflow.id, f'Training', PATH_ARTIFACTS)\n",
    "\n",
    "training_summary_hook = TensorboardSummaryHook(training_workflow.id, f'Training', PATH_ARTIFACTS)\n",
    "\n",
    "validation_summary_hook = TensorboardSummaryHook(validation_workflow.id, f'Validation', PATH_ARTIFACTS)\n",
    "\n",
    "validation_loggin_hook = LoggingHook(validation_workflow.id, f'Validation', PATH_ARTIFACTS)\n",
    "\n",
    "save_model_hook = SaveTorchModelHook(training_workflow.id, f'Training', PATH_ARTIFACTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc, torch\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from IPython.display import clear_output\n",
    "\n",
    "for i in range(NUM_EPOCHS):\n",
    "    clear_output(wait=True)\n",
    "    training_workflow.run()\n",
    "    validation_workflow.run()\n",
    "\n",
    "torch.save(model.state_dict(), 'models/vnet_valid13092020.pt')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ca98ab5b52ba06eb0afe5b53ab24af958ee42f611249236309fc6459c670307"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('miccai': virtualenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
